name: Enterprise-Grade Unified CI/CD Pipeline with Advanced Deployment Strategies

on:
  push:
    branches: [ main, develop, feature/* ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 2 * * *'  # Daily security and health checks
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: true
        default: 'staging'
        type: choice
        options: [development, staging, canary, production]
      deployment_strategy:
        description: 'Deployment strategy'
        required: true
        default: 'blue-green'
        type: choice
        options: [blue-green, canary, rolling, recreate]
      version:
        description: 'Version to deploy (default: current commit SHA)'
        required: false
        type: string
      rollback:
        description: 'Rollback deployment'
        required: false
        type: boolean
        default: false
      canary_percentage:
        description: 'Canary deployment percentage (5-50%)'
        required: false
        type: string
        default: '10'
      skip_tests:
        description: 'Skip tests (emergency deployments only)'
        required: false
        type: boolean
        default: false

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}
  KUBE_NAMESPACE: samoey-copilot
  MONITORING_NAMESPACE: monitoring

# Global permissions for the workflow
permissions:
  contents: read
  packages: write
  id-token: write
  actions: write
  pull-requests: write
  checks: write

jobs:
  # Phase 1: Comprehensive Validation & Testing
  comprehensive-validation:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.9, '3.10', '3.11']
        node-version: [18, 20]
      fail-fast: false
      max-parallel: 3

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: samoey_copilot_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

      etcd:
        image: quay.io/coreos/etcd:v3.5.9
        env:
          ETCD_NAME: etcd0
          ETCD_INITIAL_ADVERTISE_PEER_URLS: http://etcd:2380
          ETCD_LISTEN_PEER_URLS: http://0.0.0.0:2380
          ETCD_LISTEN_CLIENT_URLS: http://0.0.0.0:2379
          ETCD_INITIAL_CLUSTER: etcd0=http://etcd:2380
          ETCD_INITIAL_CLUSTER_STATE: new
          ETCD_INITIAL_CLUSTER_TOKEN: etcd-cluster-1
        ports:
          - 2379:2379
          - 2380:2380

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for better analysis

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'

    - name: Set up Node.js ${{ matrix.node-version }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ matrix.node-version }}
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/pip
          ~/.npm
          ~/.local/share/virtualenvs
        key: ${{ runner.os }}-deps-${{ matrix.python-version }}-${{ matrix.node-version }}-${{ hashFiles('**/requirements*.txt', '**/package-lock.json') }}
        restore-keys: |
          ${{ runner.os }}-deps-${{ matrix.python-version }}-${{ matrix.node-version }}-
          ${{ runner.os }}-deps-

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip setuptools wheel
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
        pip install -r app/requirements.txt
        pip install bandit safety semgrep truffleHog3 black isort flake8 mypy pylint radon xenon lizard pipdeptree pip-licenses locust pytest-benchmark psutil memory-profiler pytest-cov pytest-xdist pre-commit

    - name: Install Node.js dependencies
      run: |
        cd frontend
        npm ci
        npm install -g npm@latest

    - name: Run pre-commit checks
      run: |
        pre-commit run --all-files --show-diff-on-failure
      continue-on-error: true

    - name: Run backend tests with coverage
      run: |
        cd app
        python -m pytest --cov=. --cov-report=xml --cov-report=html --cov-report=term-missing -v --tb=short -x
        cd ..
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/samoey_copilot_test
        REDIS_URL: redis://localhost:6379
        ETCD_URL: http://localhost:2379
        SECRET_KEY: test-secret-key-for-ci-cd
        ENVIRONMENT: testing

    - name: Run frontend tests
      run: |
        cd frontend
        npm run test:ci
        cd ..
      env:
        CI: true
        NEXT_PUBLIC_API_URL: http://localhost:8000

    - name: Run integration tests
      run: |
        # Start backend server for integration tests
        cd app
        python -m uvicorn main:app --host 0.0.0.0 --port 8000 --workers 1 &
        BACKEND_PID=$!
        sleep 20

        # Run integration tests
        cd ../tests
        python -m pytest test_integration.py -v --tb=short

        # Cleanup
        kill $BACKEND_PID 2>/dev/null || true
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/samoey_copilot_test
        REDIS_URL: redis://localhost:6379
        ETCD_URL: http://localhost:2379
        SECRET_KEY: test-secret-key-for-ci-cd
        API_BASE_URL: http://localhost:8000
        ENVIRONMENT: testing

    - name: Run security scanning
      run: |
        # Python security scanning
        echo "🔒 Running Python security scanning..."
        bandit -r app/ -f json -o bandit-report.json || true
        bandit -r app/ -f html -o bandit-report.html || true
        safety check --json --output safety-report.json || true
        safety check --html --output safety-report.html || true
        semgrep --config=auto --json --output=semgrep-report.json app/ || true
        semgrep --config=p/security --json --output=semgrep-security-report.json app/ || true
        trufflehog filesystem --directory=. --json --output=trufflehog-report.json --exclude=tests,frontend/node_modules || true

        # Node.js security scanning
        echo "🔒 Running Node.js security scanning..."
        cd frontend
        npm audit --audit-level moderate --json > ../npm-audit-report.json || true
        npm audit --audit-level moderate --output markdown > ../npm-audit-report.md || true
        cd ..

        # Container security scanning
        echo "🔒 Running container security scanning..."
        docker run --rm -v /var/run/docker.sock:/var/run/docker.sock -v $PWD:/tmp aquasec/trivy:latest image --format json --output trivy-backend-report.json app/Dockerfile || true
        docker run --rm -v /var/run/docker.sock:/var/run/docker.sock -v $PWD:/tmp aquasec/trivy:latest image --format json --output trivy-frontend-report.json frontend/Dockerfile || true

    - name: Run code quality analysis
      run: |
        # Python code quality
        echo "📊 Running Python code quality analysis..."
        black --check app/ --diff --color || true
        isort --check-only app/ --diff --color-only || true
        flake8 app/ --format=json --output=flake8-report.json || true
        flake8 app/ --format=html --output=flake8-report.html || true
        mypy app/ --ignore-missing-imports --json-report=mypy-report.json || true
        mypy app/ --ignore-missing-imports --html-report=mypy-report-html || true
        pylint app/ --output-format=json --output=pylint-report.json || true
        pylint app/ --output-format=html --output=pylint-report.html || true

        # Complexity analysis
        echo "📊 Running complexity analysis..."
        radon cc app/ -a -nb -o json > radon-complexity.json || true
        radon cc app/ -a -nb -o html > radon-complexity.html || true
        radon mi app/ -o json > radon-maintainability.json || true
        radon mi app/ -o html > radon-maintainability.html || true
        xenon --max-absolute B --max-modules B --max-average A app/ || true
        lizard app/ --output json > lizard-report.json || true
        lizard app/ --output html > lizard-report.html || true

        # JavaScript/TypeScript quality
        echo "📊 Running JavaScript/TypeScript quality analysis..."
        cd frontend
        npm run lint -- --format=json --output-file=../eslint-report.json || true
        npm run lint -- --format=html --output-file=../eslint-report.html || true
        npm run format:check || true
        npm run type-check || true
        cd ..

    - name: Run performance testing
      run: |
        # Start backend for performance testing
        cd app
        python -m uvicorn main:app --host 0.0.0.0 --port 8000 --workers 1 &
        PERF_BACKEND_PID=$!
        sleep 15

        # Database performance tests
        echo "⚡ Running database performance tests..."
        python -m pytest tests/test_performance.py -v --benchmark-only --benchmark-json=benchmark-results.json || true

        # Locust load testing
        echo "⚡ Running Locust load testing..."
        cat > locustfile.py << 'EOF'
        from locust import HttpUser, task, between
        import random
        import json

        class ApiUser(HttpUser):
            wait_time = between(1, 3)

            def on_start(self):
                """Initialize user session"""
                self.headers = {}

            @task(3)
            def get_health(self):
                """Health check endpoint"""
                self.client.get("/api/health", headers=self.headers)

            @task(2)
            def get_analytics(self):
                """Analytics endpoint"""
                self.client.get("/api/v1/analytics", headers=self.headers)

            @task(2)
            def get_conversations(self):
                """Conversations endpoint"""
                self.client.get("/api/v1/conversations", headers=self.headers)

            @task(1)
            def create_message(self):
                """Create message endpoint"""
                self.client.post("/api/v1/messages",
                    json={
                        "content": f"Performance test message {random.randint(1, 1000)}",
                        "conversation_id": random.randint(1, 10)
                    },
                    headers=self.headers)

            @task(1)
            def get_user_profile(self):
                """User profile endpoint"""
                self.client.get("/api/v1/users/me", headers=self.headers)
        EOF

        locust --host http://localhost:8000 --users 10 --spawn-rate 2 --run-time 2m --headless --html locust-report.html --csv locust-stats || true

        # Memory profiling
        echo "⚡ Running memory profiling..."
        python -m memory_profiler main.py > memory-profile.txt || true

        # Cleanup
        kill $PERF_BACKEND_PID 2>/dev/null || true
        cd ..

      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/samoey_copilot_perf
        REDIS_URL: redis://localhost:6379
        ETCD_URL: http://localhost:2379
        SECRET_KEY: perf-test-secret-key
        ENVIRONMENT: testing

    - name: Build and test frontend performance
      run: |
        cd frontend
        echo "⚡ Building frontend for performance analysis..."
        npm run build

        # Lighthouse CI performance audit
        echo "⚡ Running Lighthouse CI audit..."
        npx @lhci/cli@0.12.x autorun || true

        # Bundle analysis
        echo "⚡ Running bundle analysis..."
        npm run analyze:bundle || true
        cd ..

    - name: Upload validation artifacts
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: validation-reports-${{ matrix.python-version }}-${{ matrix.node-version }}
        path: |
          **/*report*.json
          **/*report*.html
          **/*profile*.txt
          **/benchmark-results.json
          **/locust-*.html
          **/locust-*.csv
          coverage.xml
          coverage.html
          .coverage

  # Phase 2: Build and Container Security
  build-and-scan:
    needs: comprehensive-validation
    runs-on: ubuntu-latest
    if: github.event_name != 'pull_request' || github.event.action == 'synchronize'

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Build backend image
      id: build-backend
      uses: docker/build-push-action@v5
      with:
        context: ./app
        platforms: linux/amd64,linux/arm64
        push: false
        load: true
        tags: ${{ steps.meta.outputs.tags }}-backend
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        build-args: |
          BUILDKIT_INLINE_CACHE=1

    - name: Build frontend image
      id: build-frontend
      uses: docker/build-push-action@v5
      with:
        context: ./frontend
        platforms: linux/amd64,linux/arm64
        push: false
        load: true
        tags: ${{ steps.meta.outputs.tags }}-frontend
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        build-args: |
          BUILDKIT_INLINE_CACHE=1
          NEXT_PUBLIC_API_URL=${{ vars.NEXT_PUBLIC_API_URL }}

    - name: Run comprehensive container security scanning
      run: |
        echo "🔒 Running comprehensive container security scanning..."

        # Trivy scanning for vulnerabilities
        docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
          -v $PWD:/tmp aquasec/trivy:latest image \
          --format json --output trivy-backend-vulnerabilities.json \
          --severity CRITICAL,HIGH,MEDIUM \
          ${{ steps.build-backend.outputs.digest }}

        docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
          -v $PWD:/tmp aquasec/trivy:latest image \
          --format json --output trivy-frontend-vulnerabilities.json \
          --severity CRITICAL,HIGH,MEDIUM \
          ${{ steps.build-frontend.outputs.digest }}

        # Snyk scanning
        docker run --rm -e "SNYK_TOKEN=${{ secrets.SNYK_TOKEN }}" \
          snyk/snyk:latest docker test \
          --json --file=Dockerfile \
          ${{ steps.build-backend.outputs.digest }} > snyk-backend-report.json || true

        docker run --rm -e "SNYK_TOKEN=${{ secrets.SNYK_TOKEN }}" \
          snyk/snyk:latest docker test \
          --json --file=frontend/Dockerfile \
          ${{ steps.build-frontend.outputs.digest }} > snyk-frontend-report.json || true

    - name: Push container images
      if: success()
      uses: docker/build-push-action@v5
      with:
        context: ./app
        platforms: linux/amd64,linux/arm64
        push: true
        tags: ${{ steps.meta.outputs.tags }}-backend
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

    - name: Push frontend container images
      if: success()
      uses: docker/build-push-action@v5
      with:
        context: ./frontend
        platforms: linux/amd64,linux/arm64
        push: true
        tags: ${{ steps.meta.outputs.tags }}-frontend
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

    - name: Upload build artifacts
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: build-and-scan-reports
        path: |
          trivy-*-vulnerabilities.json
          snyk-*-report.json

  # Phase 3: Advanced Deployment Strategies
  deploy:
    needs: build-and-scan
    runs-on: ubuntu-latest
    if: github.event_name != 'pull_request'
    environment: ${{ github.event.inputs.environment || 'staging' }}

    strategy:
      matrix:
        deployment-strategy: ${{ github.event.inputs.deployment_strategy || 'blue-green' }}
      fail-fast: false

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Kubernetes tools
      uses: azure/setup-kubectl@v3
      with:
        version: '1.28.0'

    - name: Set up Helm
      uses: azure/setup-helm@v3
      with:
        version: '3.12.0'

    - name: Configure kubectl
      run: |
        mkdir -p $HOME/.kube
        echo "${{ secrets.KUBE_CONFIG }}" | base64 -d > $HOME/.kube/config
        kubectl config use-context ${{ secrets.KUBE_CONTEXT }}

    - name: Deploy with ${{ matrix.deployment-strategy }} strategy
      run: |
        echo "🚀 Starting ${{ matrix.deployment-strategy }} deployment..."

        # Set deployment parameters
        ENVIRONMENT=${{ github.event.inputs.environment || 'staging' }}
        VERSION=${{ github.event.inputs.version || github.sha }}
        CANARY_PERCENTAGE=${{ github.event.inputs.canary_percentage || '10' }}
        ROLLBACK=${{ github.event.inputs.rollback || 'false' }}

        # Deploy based on strategy
        case "${{ matrix.deployment-strategy }}" in
          "blue-green")
            echo "🔄 Executing Blue-Green deployment..."
            ./scripts/deploy-blue-green.sh $ENVIRONMENT $VERSION $ROLLBACK
            ;;
          "canary")
            echo "🐦 Executing Canary deployment..."
            ./scripts/deploy-canary.sh $ENVIRONMENT $VERSION $CANARY_PERCENTAGE $ROLLBACK
            ;;
          "rolling")
            echo "🎯 Executing Rolling deployment..."
            ./scripts/deploy-rolling.sh $ENVIRONMENT $VERSION $ROLLBACK
            ;;
          "recreate")
            echo "🔄 Executing Recreate deployment..."
            ./scripts/deploy-recreate.sh $ENVIRONMENT $VERSION $ROLLBACK
            ;;
        esac

    - name: Run post-deployment health checks
      run: |
        echo "🏥 Running post-deployment health checks..."

        # Wait for deployment to stabilize
        kubectl wait --for=condition=available --timeout=300s deployment/samoey-copilot-backend -n ${{ env.KUBE_NAMESPACE }}
        kubectl wait --for=condition=available --timeout=300s deployment/samoey-copilot-frontend -n ${{ env.KUBE_NAMESPACE }}

        # Run comprehensive health checks
        ./scripts/health-check.sh ${{ github.event.inputs.environment || 'staging' }}

    - name: Run post-deployment security validation
      run: |
        echo "🔒 Running post-deployment security validation..."

        # Network security validation
        ./scripts/security-validation.sh ${{ github.event.inputs.environment || 'staging' }}

        # API security testing
        ./scripts/api-security-test.sh ${{ github.event.inputs.environment || 'staging' }}

    - name: Generate deployment report
      run: |
        echo "📊 Generating deployment report..."

        cat > deployment-report.json << EOF
        {
          "deployment": {
            "environment": "${{ github.event.inputs.environment || 'staging' }}",
            "strategy": "${{ matrix.deployment-strategy }}",
            "version": "${{ github.event.inputs.version || github.sha }}",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "status": "success",
            "rollback": "${{ github.event.inputs.rollback || 'false' }}"
          },
          "metrics": {
            "deployment_time": "$(date -d@$(( $(date +%s) - ${{ job.started_at }} )) -u +%H:%M:%S)",
            "health_checks": "passed",
            "security_validation": "passed"
          }
        }
        EOF

    - name: Upload deployment artifacts
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: deployment-reports-${{ matrix.deployment-strategy }}
        path: |
          deployment-report.json
          **/health-check-*.json
          **/security-validation-*.json

  # Phase 4: Monitoring and Observability
  monitoring-setup:
    needs: deploy
    runs-on: ubuntu-latest
    if: always() && needs.deploy.result == 'success'

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up monitoring stack
      run: |
        echo "📊 Setting up monitoring and observability..."

        # Deploy Prometheus and Grafana
        kubectl apply -f monitoring/prometheus.yml
        kubectl apply -f monitoring/grafana/
        kubectl apply -f monitoring/alertmanager.yml

        # Wait for monitoring stack to be ready
        kubectl wait --for=condition=available --timeout=180s deployment/prometheus-server -n ${{ env.MONITORING_NAMESPACE }}
        kubectl wait --for=condition=available --timeout=180s deployment/grafana -n ${{ env.MONITORING_NAMESPACE }}

    - name: Configure alerts and dashboards
      run: |
        echo "🔔 Configuring alerts and dashboards..."

        # Apply alert rules
        kubectl apply -f monitoring/alert.rules

        # Import Grafana dashboards
        ./scripts/import-grafana-dashboards.sh

    - name: Run synthetic monitoring
      run: |
        echo "🔍 Running synthetic monitoring..."

        # Deploy synthetic monitoring probes
        kubectl apply -f monitoring/synthetic-monitoring/

        # Wait for probes to be ready
        sleep 30

        # Run initial synthetic tests
        ./scripts/run-synthetic-tests.sh

    - name: Generate monitoring report
      run: |
        echo "📈 Generating monitoring report..."

        cat > monitoring-report.json << EOF
        {
          "monitoring": {
            "status": "active",
            "components": ["prometheus", "grafana", "alertmanager", "synthetic-monitoring"],
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
          },
          "alerts": {
            "configured": true,
            "active_alerts": 0
          },
          "dashboards": {
            "imported": true,
            "count": 5
          }
        }
        EOF

    - name: Upload monitoring artifacts
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: monitoring-reports
        path: |
          monitoring-report.json
          **/synthetic-test-*.json

  # Phase 5: Cleanup and Reporting
  cleanup-and-report:
    needs: [comprehensive-validation, build-and-scan, deploy, monitoring-setup]
    runs-on: ubuntu-latest
    if: always()

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Generate comprehensive pipeline report
      run: |
        echo "📋 Generating comprehensive pipeline report..."

        cat > pipeline-report.json << EOF
        {
          "pipeline": {
            "run_id": "${{ github.run_id }}",
            "run_number": "${{ github.run_number }}",
            "trigger": "${{ github.event_name }}",
            "branch": "${{ github.ref_name }}",
            "commit": "${{ github.sha }}",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
          },
          "jobs": {
            "comprehensive-validation": "${{ needs.comprehensive-validation.result }}",
            "build-and-scan": "${{ needs.build-and-scan.result }}",
            "deploy": "${{ needs.deploy.result }}",
            "monitoring-setup": "${{ needs.monitoring-setup.result }}"
          },
          "summary": {
            "total_duration": "$(date -d@$(( $(date +%s) - ${{ job.started_at }} )) -u +%H:%M:%S)",
            "status": "$([ "${{ needs.comprehensive-validation.result }}" = "success" ] && [ "${{ needs.build-and-scan.result }}" = "success" ] && [ "${{ needs.deploy.result }}" = "success" ] && echo "success" || echo "failure")",
            "environment": "${{ github.event.inputs.environment || 'staging' }}",
            "deployment_strategy": "${{ github.event.inputs.deployment_strategy || 'blue-green' }}"
          }
        }
        EOF

    - name: Create deployment summary
      run: |
        echo "📝 Creating deployment summary..."

        cat > deployment-summary.md << EOF
        # Deployment Summary

        ## Pipeline Information
        - **Run ID**: ${{ github.run_id }}
        - **Run Number**: ${{ github.run_number }}
        - **Trigger**: ${{ github.event_name }}
        - **Branch**: ${{ github.ref_name }}
        - **Commit**: ${{ github.sha }}
        - **Timestamp**: $(date -u +%Y-%m-%dT%H:%M:%SZ)

        ## Job Results
        - **Comprehensive Validation**: ${{ needs.comprehensive-validation.result }}
        - **Build and Scan**: ${{ needs.build-and-scan.result }}
        - **Deploy**: ${{ needs.deploy.result }}
        - **Monitoring Setup**: ${{ needs.monitoring-setup.result }}

        ## Deployment Details
        - **Environment**: ${{ github.event.inputs.environment || 'staging' }}
        - **Strategy**: ${{ github.event.inputs.deployment_strategy || 'blue-green' }}
        - **Version**: ${{ github.event.inputs.version || github.sha }}
        - **Rollback**: ${{ github.event.inputs.rollback || 'false' }}
        - **Total Duration**: $(date -d@$(( $(date +%s) - ${{ job.started_at }} )) -u +%H:%M:%S)

        ## Overall Status
        **$([ "${{ needs.comprehensive-validation.result }}" = "success" ] && [ "${{ needs.build-and-scan.result }}" = "success" ] && [ "${{ needs.deploy.result }}" = "success" ] && [ "${{ needs.monitoring-setup.result }}" = "success" ] && echo "✅ Success" || echo "❌ Failed")**
        EOF

    - name: Upload final artifacts
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: pipeline-final-report
        path: |
          pipeline-report.json
          deployment-summary.md

    - name: Comment on PR with deployment status
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const summary = fs.readFileSync('deployment-summary.md', 'utf8');

          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: summary
          });

    - name: Cleanup old artifacts
      if: always()
      run: |
        echo "🧹 Cleaning up old artifacts..."

        # Remove old container images (keep last 5)
        gh api repos/${{ github.repository }}/packages/container/samoey-copilot-backend/versions --jq '.[].metadata.container.tags[]' | head -n -5 | xargs -I {} gh api -X DELETE repos/${{ github.repository }}/packages/container/samoey-copilot-backend/versions/{} || true
        gh api repos/${{ github.repository }}/packages/container/samoey-copilot-frontend/versions --jq '.[].metadata.container.tags[]' | head -n -5 | xargs -I {} gh api -X DELETE repos/${{ github.repository }}/packages/container/samoey-copilot-frontend/versions/{} || true

        # Cleanup old workflow runs (keep last 20)
        gh run list --limit 50 --json databaseId | jq -r '.[].databaseId' | tail -n +21 | xargs -I {} gh run delete {} || true
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
